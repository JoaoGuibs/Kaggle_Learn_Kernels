{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NnMcwCIpj37W"
   },
   "outputs": [],
   "source": [
    "!kill -9 -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2542,
     "status": "ok",
     "timestamp": 1570048618262,
     "user": {
      "displayName": "Joao Guilherme",
      "photoUrl": "",
      "userId": "02077358952033531630"
     },
     "user_tz": -60
    },
    "id": "8qhrrSjbLq78",
    "outputId": "0e4b5640-b0f2-4e3c-b99b-c85d69d2ce81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Conv2DTranspose, MaxPooling2D, Flatten,Dropout, GaussianNoise, concatenate, Input,UpSampling2D, Cropping2D, UpSampling2D, BatchNormalization\n",
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.utils import to_categorical, Sequence\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras import backend as K\n",
    "from skimage.transform import warp\n",
    "import json\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image, ImageDraw \n",
    "import glob\n",
    "from xml.dom import minidom\n",
    "import cv2\n",
    "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
    "!pip install gputil\n",
    "!pip install psutil\n",
    "!pip install humanize\n",
    "import psutil\n",
    "import humanize\n",
    "import GPUtil as GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Classes:\n",
    "class Custom_Generator(Sequence):\n",
    "  \"\"\"\n",
    "    Custom data generator, used for convenience purposes\n",
    "    TODO: Add custom data augmentation routine to the data\n",
    "  \"\"\"\n",
    "  def __init__(self, image_filenames, masks, batch_size, nrows, ncols, augment = False):\n",
    "    self.image_filenames, self.masks = image_filenames, masks\n",
    "    self.batch_size = batch_size\n",
    "    self.nrows = nrows\n",
    "    self.ncols = ncols\n",
    "    self.augment = augment\n",
    "    \n",
    "  def __len__(self):\n",
    "    return np.ceil(len(self.image_filenames) / float(self.batch_size)).astype(np.int64)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    batch_x = self.image_filenames[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "    batch_y = self.masks[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "    \n",
    "    out_image = np.array([ cv2.resize( cv2.imread(file_name), (self.ncols, self.nrows) )\n",
    "                          * (1./255) for file_name in batch_x])\n",
    "    out_mask =  np.array([ cv2.resize( cv2.imread(mask_name), (self.ncols, self.nrows) )\n",
    "                          * (1./255) for mask_name in batch_y]) \n",
    "    \n",
    "    #Use a data augmentation procedure, adding readout noise and affine transformation\n",
    "    if (self.augment == True):\n",
    "      for i in range(out_image.shape[0]):\n",
    "        #out_image[i] = self.add_readout_noise(out_image[i])\n",
    "        out_image[i], out_mask[i] = self.apply_affine_transform(out_image[i],out_mask[i])\n",
    " \n",
    "    return out_image, out_mask\n",
    "    \n",
    "  def add_readout_noise(self, image):\n",
    "    \"\"\"\n",
    "    Adds readout noise to the input image.\n",
    "    RON is modeled by a normal distribution with a zero-mean and \n",
    "    with std = RON.\n",
    "    TODO: Understand the implications of adding RON for segmentation\n",
    "    \"\"\"\n",
    "    ron_image = np.random.normal(0, (2./255), (image.shape) ) #RON  = 2 DN.rms \n",
    "    image += ron_image\n",
    "    \n",
    "    return image\n",
    "  \n",
    "  def apply_affine_transform(self, image, mask):\n",
    "    \"\"\"\n",
    "      Applies an affine transform to the image and the mask.\n",
    "      The scale, rotation and translation values are chosen \n",
    "      randomly, from a normal distribution\n",
    "    \"\"\"\n",
    "    scale = 1#np.random.normal(1, 0.1, 1)\n",
    "    theta = np.random.normal(0, 30, 1) * math.pi / 180 #Convert angle to radians\n",
    "    tx, ty = [0,0]#np.random.normal(0, 50, 2) #translation pixels\n",
    "    \n",
    "    Affine = np.identity(3)\n",
    "    Affine[0,0] = scale * math.cos(theta)\n",
    "    Affine[0,1] = -scale * math.sin(theta)\n",
    "    Affine[1,0] = scale * math.sin(theta)\n",
    "    Affine[1,1] = scale * math.cos(theta)\n",
    "    Affine[0,2] = tx\n",
    "    Affine[1,2] = ty\n",
    "    \n",
    "    image = warp(image, Affine) #warps the image and mask using the affine\n",
    "    mask = warp(mask, Affine)\n",
    "    \n",
    "    return image, mask\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 18156,
     "status": "ok",
     "timestamp": 1570049355513,
     "user": {
      "displayName": "Joao Guilherme",
      "photoUrl": "",
      "userId": "02077358952033531630"
     },
     "user_tz": -60
    },
    "id": "yfaGvNyyLOnS",
    "outputId": "93215f69-2307-4d80-8aec-066bc5e3f7e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gputil in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
      "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##Functions\n",
    "def build_cnn_model(n_classes, nrows, ncols):\n",
    "  \"\"\"\n",
    "    This function builds the CNN model.\n",
    "  \"\"\" \n",
    "  inputs = Input((nrows,ncols,3))\n",
    "  c1 = keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same',data_format = 'channels_last', name = 'conv1_1') (inputs)\n",
    "  c1 = keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same',data_format = 'channels_last', name = 'conv1_2') (c1)\n",
    "  c1 = BatchNormalization()(c1)\n",
    "  p1 = keras.layers.MaxPooling2D((2, 2), data_format = 'channels_last') (c1)\n",
    "\n",
    "  c2 = keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', data_format = 'channels_last', name = 'conv2_1') (p1)\n",
    "  c2 = keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', data_format = 'channels_last', name = 'conv2_2') (c2)\n",
    "  c2 = BatchNormalization()(c2)\n",
    "  p2 = keras.layers.MaxPooling2D((2, 2), data_format = 'channels_last') (c2)\n",
    "  \n",
    "  c3 = keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', data_format = 'channels_last', name = 'conv3_1') (p2)\n",
    "  c3 = keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', data_format = 'channels_last', name = 'conv3_2') (c3)\n",
    "  c3 = keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', data_format = 'channels_last', name = 'conv3_3') (c3)\n",
    "  c3 = BatchNormalization()(c3)\n",
    "  p3 = keras.layers.MaxPooling2D((2, 2), data_format = 'channels_last') (c3)\n",
    "\n",
    "  c4 = keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same', data_format = 'channels_last', name = 'conv4_1') (p3)\n",
    "  c4 = keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same', data_format = 'channels_last', name = 'conv4_2') (c4)\n",
    "  c4 = keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same', data_format = 'channels_last', name = 'conv4_3') (c4)\n",
    "  c4 = BatchNormalization()(c4)\n",
    "  p4 = keras.layers.MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "\n",
    "  c5 = keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same', data_format = 'channels_last', name = 'conv5_1') (p4)\n",
    "  c5 = keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same', data_format = 'channels_last', name = 'conv5_2') (c5)\n",
    "  c5 = keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same', data_format = 'channels_last', name = 'conv5_3') (c5)\n",
    "  c5 = BatchNormalization()(c5)\n",
    "  \n",
    "  u6 = concatenate([Conv2DTranspose(256, (2,2), strides = 2, padding='same', data_format = 'channels_last')(c5), c4])\n",
    "  c6 = keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same', data_format = 'channels_last') (u6)\n",
    "  c6 = keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same', data_format = 'channels_last') (c6)\n",
    "  c6 = BatchNormalization()(c6)\n",
    "\n",
    "  u7 = concatenate([Conv2DTranspose(128, (2,2), strides = 2, padding='same', data_format = 'channels_last')(c6), c3])\n",
    "  c7 = keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', data_format = 'channels_last') (u7)\n",
    "  c7 = keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', data_format = 'channels_last') (c7)\n",
    "  c7 = BatchNormalization()(c7)\n",
    "  \n",
    "  u8 = concatenate([Conv2DTranspose(64, (2,2), strides = 2, padding='same', data_format = 'channels_last')(c7), c2])\n",
    "  c8 = keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', data_format = 'channels_last') (u8)\n",
    "  c8 = keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', data_format = 'channels_last') (c8)\n",
    "  c8 = BatchNormalization()(c8)\n",
    "  \n",
    "  u9 = concatenate([Conv2DTranspose(32, (2,2), strides = 2, padding='same', data_format = 'channels_last')(c8), c1])\n",
    "  c9 = keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', data_format = 'channels_last') (u9)\n",
    "  c9 = keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', data_format = 'channels_last') (c9)\n",
    "  c9 = BatchNormalization()(c9)\n",
    "  \n",
    "  o = Conv2D(n_classes, (1, 1) , padding = 'same', activation = 'sigmoid')(c9)\n",
    "  \n",
    "  model = Model(inputs = [inputs], outputs = [o])\n",
    "  model.summary()\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Intersection over union loss and accuracy \n",
    "def IoU_loss(y_true, y_pred, eps=1e-6):\n",
    "    \n",
    "    intersection = K.sum(y_true * y_pred, axis=[1,2,3])\n",
    "    union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3]) - intersection\n",
    "    \n",
    "    return 1-K.mean( (intersection + eps) / (union + eps), axis=0)\n",
    "  \n",
    "def IoU_acc(y_true, y_pred, eps=1e-6):\n",
    "    \n",
    "    intersection = K.sum(y_true * y_pred, axis=[1,2,3])\n",
    "    union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3]) - intersection\n",
    "    \n",
    "    return K.mean( (intersection + eps) / (union + eps), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_save_results(trained_model, base_dir, test_data_list, mask_data_list, ncols, nrows):\n",
    "  \"\"\"\n",
    "    Plots the segmentation results and saves some output images to the output folder.\n",
    "  \"\"\"\n",
    "  import re\n",
    "  \n",
    "  #Plots #N input image and mask and output \n",
    "  for i in range(10):\n",
    "  #Reads and adds extra dimension to the input data\n",
    "    input_test = cv2.resize(cv2.imread(test_data_list[i]), (ncols,nrows)) * (1./255)\n",
    "    input_test = input_test[np.newaxis,:]\n",
    "    input_mask = cv2.resize(cv2.imread(mask_data_list[i]), (ncols,nrows)) * (1./255)\n",
    "    input_mask = input_mask[np.newaxis,:]\n",
    "\n",
    "    output_mask = trained_model.predict(input_test)\n",
    "\n",
    "    plt.figure(figsize = (12,12))\n",
    "    plt.title('Input Image')\n",
    "    plt.imshow(input_test[0])\n",
    "\n",
    "    plt.figure(figsize = (12,12))\n",
    "    plt.title('Output mask')\n",
    "    plt.imshow(output_mask[0])\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.figure(figsize = (12,12))\n",
    "    plt.title('Ground-truth mask')\n",
    "    plt.imshow(input_mask[0])\n",
    "    \n",
    "    output_file = \"out_\" + re.sub(base_dir+'/images/render/', '', test_data_list[i]) \n",
    "    cv2.imwrite(base_dir+'/Outputs/'+ output_file , (output_mask[0] * 255).astype(np.uint8) )\n",
    "    \n",
    "  return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_results(history):\n",
    "    \"\"\"\n",
    "    Obtains the training history and plots the accuracy and loss\n",
    "    of both the training and validation.\n",
    "    \"\"\"\n",
    "    acc = history.history['acc']\n",
    "    loss = history.history['loss']\n",
    "    val_acc = history.history['val_acc']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    plt.figure(figsize = (20,20) )\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.plot(acc, label = 'Train Accuracy')\n",
    "    plt.plot(val_acc, label = 'Validation Accuracy')\n",
    "    plt.xlabel('Epoch Number')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.plot(loss, label = 'Train Loss')\n",
    "    plt.plot(val_loss, label = 'Validation Loss')\n",
    "    plt.xlabel('Epoch Number')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "13z_4PQOWO61DHcPoEDgkR_FEkonf8pjT"
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 96028,
     "status": "ok",
     "timestamp": 1570049438445,
     "user": {
      "displayName": "Joao Guilherme",
      "photoUrl": "",
      "userId": "02077358952033531630"
     },
     "user_tz": -60
    },
    "id": "__uCZijTi_zu",
    "outputId": "ae6e6a46-3262-48f4-d8ff-a5e3b0cc6996"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output hidden; open in https://colab.research.google.com to view."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###Main Program\n",
    "def main():\n",
    "  #Loads the vgg16 model\n",
    "  #vgg_16_model = np.load(os.getcwd()+'/gdrive/My Drive/Colab Notebooks/Kaggle_Proj/vgg16.npy', \n",
    "    #allow_pickle=True,  encoding='latin1').item()\n",
    "  \n",
    "  is_train = input('Are we training the model? [y/n] ')\n",
    "  \n",
    "  #Number of rows and columns of input data\n",
    "  nrows = 240\n",
    "  ncols = 368\n",
    "  n_classes = 3\n",
    "  base_dir = os.getcwd()+'/gdrive/My Drive/Colab Notebooks/Kaggle_Proj/'\n",
    "  \n",
    "  print('The number of classes to classify are: ', n_classes, ' classes (+background)')\n",
    "  \n",
    "  if(is_train == 'y'):\n",
    "    \n",
    "    cnn_model = build_cnn_model(n_classes, nrows,ncols)\n",
    "    \n",
    "    images_list = glob.glob(base_dir +'/images/render/*.png')\n",
    "    images_list.sort()\n",
    "    labels_list = glob.glob(base_dir +'/images/ground/*.png')\n",
    "    labels_list.sort()\n",
    "    \n",
    "    num_training_samples = len(labels_list)\n",
    "    \n",
    "    print('The total number of input samples are: %.d'%num_training_samples)\n",
    "    \n",
    "    #Create array of random numbers\n",
    "    arr = np.arange(num_training_samples)\n",
    "    np.random.shuffle(arr)\n",
    "    arr.tolist()\n",
    "    \n",
    "    #Take a given fraction of data for validation\n",
    "    val_fraction = 0.1\n",
    "    \n",
    "    val_images_list = np.array(images_list)[arr][0:int(val_fraction * num_training_samples)]\n",
    "    val_labels_list = np.array(labels_list)[arr][0:int(val_fraction * num_training_samples)]\n",
    "    \n",
    "    #The remainder of data is used for training\n",
    "    images_list = np.array(images_list)[arr][int(val_fraction * num_training_samples):]\n",
    "    labels_list = np.array(labels_list)[arr][int(val_fraction * num_training_samples):]\n",
    "    \n",
    "    num_training_samples -= int(val_fraction*num_training_samples) #Update number of training samples\n",
    "        \n",
    "    #Batch Size and number of training epochs\n",
    "    batch_size = 32\n",
    "    epochs = 30\n",
    "    \n",
    "    #Create the input and validation data generator\n",
    "    train_gen = Custom_Generator(images_list, labels_list, batch_size, nrows, ncols, augment = True)\n",
    "    val_gen = Custom_Generator(val_images_list, val_labels_list, batch_size, nrows, ncols) \n",
    "    \n",
    "    out_file = base_dir + '/Models/Moon_images_seg_cnn_{epoch:02d}-{val_loss:.2f}.h5'\n",
    "    \n",
    "    print('Starting the training')\n",
    "    \n",
    "    #Compile the model, with the optimizers, loss and metrics\n",
    "    cnn_model.compile(optimizer = Adam(1e-3, decay=1e-6), loss = IoU_loss, metrics = ['accuracy', IoU_acc])\n",
    "    \n",
    "    #Callbacks: Check point, Early Stopping and Reduce Learning rate\n",
    "    model_checkpoint = ModelCheckpoint(out_file, monitor = 'val_loss', verbose = 0, save_best_only = True)\n",
    "    #early_stopping = EarlyStopping(monitor = 'val_loss')\n",
    "    reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.2, \n",
    "                                  patience = 1, min_lr = 0.00001)\n",
    "    \n",
    "    #Fits the train generator to the model\n",
    "    history = cnn_model.fit_generator(train_gen, \n",
    "                                      steps_per_epoch = num_training_samples//batch_size,\n",
    "                                      epochs = epochs,\n",
    "                                      validation_data = val_gen,\n",
    "                                      workers = 16,\n",
    "                                      verbose = 1,\n",
    "                                      callbacks = [model_checkpoint, reduce_lr] )\n",
    "    \n",
    "    plot_train_results(history)\n",
    "    \n",
    "  else:\n",
    "    \n",
    "    test_data_list = glob.glob(base_dir + '/images/render/*.png')\n",
    "    #glob.glob(base_dir + '/real_moon_images/PCAM*.png')\n",
    "    #glob.glob(base_dir + '/images/render/*.png')\n",
    "    test_data_list.sort()\n",
    "    mask_data_list = glob.glob(base_dir + '/images/ground/*.png')\n",
    "    #glob.glob(base_dir + '/real_moon_images/g_PCAM*.png')\n",
    "    #glob.glob(base_dir + '/images/ground/*.png')\n",
    "    mask_data_list.sort()\n",
    "    \n",
    "    print('Loading Trained model')\n",
    "    input_model_file = base_dir + '/Models/Moon_images_seg_cnn_06-0.35.h5'\n",
    "    import tensorflow.losses\n",
    "    tensorflow.losses.custom_loss = IoU_loss\n",
    "    trained_model = keras.models.load_model(input_model_file, \n",
    "                                            custom_objects=dict(IoU_loss=IoU_loss, IoU_acc = IoU_acc))\n",
    "    \n",
    "    plot_save_results(trained_model, base_dir, test_data_list, mask_data_list, ncols, nrows)\n",
    "\n",
    "  return 0\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "  local_device_protos = device_lib.list_local_devices()\n",
    "  print(local_device_protos)\n",
    "  \n",
    "  #Function used in google colab to get available GPU devices\n",
    "  GPUs = GPU.getGPUs()\n",
    "  # XXX: only one GPU on Colab and isn’t guaranteed\n",
    "  gpu = GPUs[0]\n",
    "  def printm():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ),\n",
    "          \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
    "    print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
    "  printm() \n",
    "\n",
    "  main()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Moon_Images_Kaggle.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
